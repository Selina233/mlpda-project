{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MyDataset\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëáËØçÂêëÈáèËΩ¨Âåñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12999/25000 [00:03<00:02, 4207.33it/s]  \n"
     ]
    }
   ],
   "source": [
    "train_sentence = np.load(\"./npys/train/sentence_code.npy\",allow_pickle=True)\n",
    "vocabulary_vectors = np.load(\"./npys/vocabulary_vectors.npy\",allow_pickle=True)\n",
    "y_train = np.load(\"./npys/train/labels.npy\",allow_pickle=True).tolist()\n",
    "X_train=[]\n",
    "# for sentence in train_sentence:\n",
    "#     temp=[]\n",
    "#     for word in sentence:\n",
    "#         if word<0:\n",
    "#             temp.append(np.zeros(100))\n",
    "#         else:\n",
    "#             temp.append(vocabulary_vectors[word])\n",
    "#     X_train.append(temp)\n",
    "cnt=0\n",
    "for sentence in tqdm (train_sentence):\n",
    "    cnt+=1\n",
    "    if(cnt<12001):\n",
    "        continue\n",
    "    \n",
    "    temp=[]\n",
    "    for word in sentence:\n",
    "        if word<0:\n",
    "            temp+=list(np.zeros(100))\n",
    "        else:\n",
    "            temp+=list(vocabulary_vectors[word])\n",
    "    X_train.append(temp)\n",
    "    if len(X_train)==1000:\n",
    "        break\n",
    "\n",
    "\n",
    "# sentence = [self.vocabulary_vectors[word_id] if word_id>=0 else np.zeros(100) for word_id in sentence]\n",
    "#         sentence = torch.as_tensor(sentence, dtype=torch.float32, device=self.device)\n",
    "#         label = torch.as_tensor(self.y[index], dtype=torch.float32, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12999/25000 [00:03<00:03, 3323.02it/s]  \n"
     ]
    }
   ],
   "source": [
    "test_sentence = np.load(\"./npys/test/sentence_code.npy\",allow_pickle=True)\n",
    "y_test = np.load(\"./npys/test/labels.npy\",allow_pickle=True).tolist()\n",
    "X_test=[]\n",
    "# for sentence in test_sentence:\n",
    "#     temp=[]\n",
    "#     for word in sentence:\n",
    "#         if word<0:\n",
    "#             temp.append(np.zeros(100))\n",
    "#         else:\n",
    "#             temp.append(vocabulary_vectors[word])\n",
    "#     X_test.append(temp)\n",
    "cnt=0\n",
    "for sentence in tqdm (test_sentence):\n",
    "    cnt+=1\n",
    "    if(cnt<12001):\n",
    "        continue\n",
    "    temp=[]\n",
    "    if len(sentence)!=600:\n",
    "        print(\"fuck\")\n",
    "        break\n",
    "    for word in sentence:\n",
    "        if word<0:\n",
    "            temp+=list(np.zeros(100))\n",
    "        else:\n",
    "            temp+=list(vocabulary_vectors[word])\n",
    "    X_test.append(temp)\n",
    "    if len(X_test)==1000:\n",
    "        break\n",
    "\n",
    "# sentence = [self.vocabulary_vectors[word_id] if word_id>=0 else np.zeros(100) for word_id in sentence]\n",
    "#         sentence = torch.as_tensor(sentence, dtype=torch.float32, device=self.device)\n",
    "#         label = torch.as_tensor(self.y[index], dtype=torch.float32, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m small_X_train\u001b[39m=\u001b[39mX_train[:\u001b[39m25\u001b[39m]\n\u001b[1;32m      2\u001b[0m small_y_train\u001b[39m=\u001b[39my_train[:\u001b[39m25\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m svm \u001b[39m=\u001b[39m SVC()\u001b[39m.\u001b[39;49mfit(small_X_train, small_y_train)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy on training set: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(svm\u001b[39m.\u001b[39mscore(small_X_train, small_y_train)))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mlpda/lib/python3.10/site-packages/sklearn/svm/_base.py:201\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    193\u001b[0m         X,\n\u001b[1;32m    194\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    199\u001b[0m     )\n\u001b[0;32m--> 201\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_targets(y)\n\u001b[1;32m    203\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[1;32m    204\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[1;32m    205\u001b[0m )\n\u001b[1;32m    206\u001b[0m solver_type \u001b[39m=\u001b[39m LIBSVM_IMPL\u001b[39m.\u001b[39mindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mlpda/lib/python3.10/site-packages/sklearn/svm/_base.py:749\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight_ \u001b[39m=\u001b[39m compute_class_weight(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight, classes\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, y\u001b[39m=\u001b[39my_)\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mcls\u001b[39m) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    750\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe number of classes has to be greater than one; got \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m class\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    751\u001b[0m         \u001b[39m%\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    752\u001b[0m     )\n\u001b[1;32m    754\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\n\u001b[1;32m    756\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "small_X_train=X_train[:25]\n",
    "small_y_train=y_train[:25]\n",
    "svm = SVC().fit(small_X_train, small_y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svm.score(small_X_train, small_y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC().fit(X_train, y_train)\n",
    "print(\"Support Vector Machine\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svm.score(X_train, y_train)))\n",
    "print(\"Accuracy on train set: {:.3f}\".format(svm.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(\"svmModel\",svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.526\n"
     ]
    }
   ],
   "source": [
    "#Train decision tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=0).fit(X_train, y_train[12000:13000])\n",
    "print(\"Decision Tree\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train[12000:13000])))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test[12000:13000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Accuracy on training set: 0.736\n",
      "Accuracy on test set: 0.505\n"
     ]
    }
   ],
   "source": [
    "#kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train[12000:13000])\n",
    "print(\"KNN\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(knn.score(X_train, y_train[12000:13000])))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(knn.score(X_test, y_test[12000:13000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)\n",
    "cnt=0\n",
    "ccnt=0\n",
    "for y in y_test:\n",
    "    if y!=1:\n",
    "        cnt+=1\n",
    "        if(cnt==50):\n",
    "            print(ccnt)\n",
    "    else:\n",
    "        ccnt+=1\n",
    "cnt      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëáËØïËØïÊîØÊåÅÂêëÈáèÊú∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train support vector machine model\n",
    "svm = SVC().fit(X_train, y_train)\n",
    "print(\"Support Vector Machine\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svm.score(X_train, y_train)))\n",
    "print(\"Accuracy on train set: {:.3f}\".format(svm.score(X_train, y_train)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('mlpda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e0baf67eca4e7fa854f644d61b9ce9c5791eff3d5812e3fb6a3332a81a5d21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
