{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MyDataset\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:02<00:00, 16.02it/s]\n"
     ]
    }
   ],
   "source": [
    "train_sentence = np.load(\"./npys/train/sentence_code.npy\",allow_pickle=True).tolist()[12000:13000]\n",
    "y_train = np.load(\"./npys/train/labels.npy\",allow_pickle=True).tolist()[12000:13000]\n",
    "X_train=[]\n",
    "for sentence in tqdm (train_sentence):\n",
    "    total_cnt=0\n",
    "    temp=list(np.zeros(400000))\n",
    "    for word in sentence:\n",
    "        if word>=0:\n",
    "            temp[word]+=1\n",
    "            #temp[word]=1\n",
    "            total_cnt+=1\n",
    "    for i in range (len(temp)):\n",
    "        temp[i]/=total_cnt\n",
    "    X_train.append(temp)\n",
    "#how to normalize?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:06<00:00, 14.96it/s]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = np.load(\"./npys/test/sentence_code.npy\",allow_pickle=True).tolist()[12000:13000]\n",
    "y_test = np.load(\"./npys/train/labels.npy\",allow_pickle=True).tolist()[12000:13000]\n",
    "X_test=[]\n",
    "for sentence in tqdm (test_sentence):\n",
    "    total_cnt=0\n",
    "    temp=list(np.zeros(400000))\n",
    "    for word in sentence:\n",
    "        if word>=0:\n",
    "            temp[word]+=1\n",
    "            #temp[word]=1\n",
    "            total_cnt+=1\n",
    "    for i in range (len(temp)):\n",
    "        temp[i]/=total_cnt\n",
    "    X_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04697986577181208,\n",
       " 0.05536912751677853,\n",
       " 0.04194630872483222,\n",
       " 0.025167785234899327,\n",
       " 0.018456375838926176,\n",
       " 0.028523489932885907,\n",
       " 0.015100671140939598,\n",
       " 0.016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.006711409395973154,\n",
       " 0.003355704697986577,\n",
       " 0.016778523489932886,\n",
       " 0.003355704697986577,\n",
       " 0.003355704697986577,\n",
       " 0.013422818791946308,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.003355704697986577,\n",
       " 0.016778523489932886,\n",
       " 0.003355704697986577,\n",
       " 0.0016778523489932886,\n",
       " 0.003355704697986577,\n",
       " 0.006711409395973154,\n",
       " 0.003355704697986577,\n",
       " 0.0016778523489932886,\n",
       " 0.0050335570469798654,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.003355704697986577,\n",
       " 0.0050335570469798654,\n",
       " 0.006711409395973154,\n",
       " 0.0016778523489932886,\n",
       " 0.003355704697986577,\n",
       " 0.0016778523489932886,\n",
       " 0.003355704697986577,\n",
       " 0.0050335570469798654,\n",
       " 0.010067114093959731,\n",
       " 0.0016778523489932886,\n",
       " 0.010067114093959731,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0050335570469798654,\n",
       " 0.01174496644295302,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.025167785234899327,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.008389261744966443,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.006711409395973154,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.006711409395973154,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0050335570469798654,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0050335570469798654,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0050335570469798654,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0050335570469798654,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.006711409395973154,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0050335570469798654,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.008389261744966443,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003355704697986577,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0050335570469798654,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0016778523489932886,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.635\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    knn = joblib.load('knn.model')\n",
    "except:\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn=KNeighborsClassifier(n_neighbors=10,metric='cosine',weights=\"distance\").fit(X_train, y_train)\n",
    "    joblib.dump(knn, 'knn.model')\n",
    "\n",
    "\n",
    "print(\"KNN\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(knn.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用binary数据 即只看一个单词有没有 不数多少个\n",
    "KNN\n",
    "Accuracy on training set: 0.793\n",
    "Accuracy on test set: 0.510\n",
    "normal\n",
    "KNN\n",
    "Accuracy on training set: 0.795\n",
    "Accuracy on test set: 0.612\n",
    "\n",
    "kNN distance n=10\n",
    "KNN\n",
    "Accuracy on training set: 1.000\n",
    "Accuracy on test set: 0.635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.667\n"
     ]
    }
   ],
   "source": [
    "#Train decision tree model\n",
    "try:\n",
    "    tree = joblib.load('tree.model')\n",
    "except:\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    tree = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "    joblib.dump(tree, 'tree.model')\n",
    "\n",
    "# print(\"Decision Tree\")\n",
    "# print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "# print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary：\n",
    "Decision Tree\n",
    "Accuracy on training set: 1.000\n",
    "Accuracy on test set: 0.640\n",
    "normal：\n",
    "Decision Tree\n",
    "Accuracy on training set: 1.000\n",
    "Accuracy on test set: 0.667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "Accuracy on training set: 0.920\n",
      "Accuracy on train set: 0.752\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    svm = joblib.load('svm.model')\n",
    "except:\n",
    "    svm = SVC().fit(X_train, y_train)\n",
    "    joblib.dump(svm, 'svm.model')\n",
    "\n",
    "print(\"Support Vector Machine\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svm.score(X_train, y_train)))\n",
    "print(\"Accuracy on train set: {:.3f}\".format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary：\n",
    "Support Vector Machine\n",
    "Accuracy on training set: 0.891\n",
    "Accuracy on train set: 0.763\n",
    "Normal:\n",
    "Support Vector Machine\n",
    "Accuracy on training set: 0.920\n",
    "Accuracy on train set: 0.752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_predict=tree.predict(X_test)\n",
    "svm_predict=svm.predict(X_test)\n",
    "knn_predict=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#get confusion matrix\n",
    "#           prediction\n",
    "#           pos   neg\n",
    "#tar pos    TP    FN\n",
    "#get neg    FP    TN\n",
    "TPlist=[0,0,0]\n",
    "FNlist=[0,0,0]\n",
    "FPlist=[0,0,0]\n",
    "TNlist=[0,0,0]\n",
    "print(TPlist[0])\n",
    "def performance(labelArr, predictArr,list_index):  # 样本一定要是数组narray类型 类标签为1，0 # labelArr[i]真实的类别,predictArr[i]预测的类别\n",
    "    # labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0; TN = 0; FP = 0; FN = 0\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1\n",
    "        elif labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1\n",
    "        elif labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1\n",
    "        elif labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1\n",
    "    TPlist[list_index]=TP\n",
    "    FNlist[list_index]=FN\n",
    "    FPlist[list_index]=FP\n",
    "    TNlist[list_index]=TN\n",
    "\n",
    "#生成各模型TP等数据\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance(y_test,tree_predict,0)\n",
    "performance(y_test,knn_predict,1)\n",
    "performance(y_test,svm_predict,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(index):\n",
    "    TP=TPlist[index]\n",
    "    FN=FNlist[index]\n",
    "    TN=TNlist[index]\n",
    "    FP=FPlist[index]\n",
    "    recall1=TP/(TP+FN)\n",
    "    recall2=TN/(FP+TN)\n",
    "    return recall1,recall2\n",
    "    \n",
    "def average_accuracy_hm(index):#index of TPlist\n",
    "    recall1,recall2=recall(index)\n",
    "    accuracy=(recall1+recall2)/2\n",
    "    accuracy_hm=2/(1/recall1+1/recall2)\n",
    "    return accuracy,accuracy_hm\n",
    "\n",
    "def precision(index):\n",
    "    TP=TPlist[index]\n",
    "    FP=FPlist[index]\n",
    "    prec=TP/(TP+FP)\n",
    "    return prec\n",
    "\n",
    "def F1_feature(index):\n",
    "    recall1,fuck=recall(index)\n",
    "    prec=precision(index)\n",
    "    F1=2*prec*recall1/(prec+recall1)\n",
    "    return F1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算各种指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: tree\n",
      "recall1 and recall 2 (0.646, 0.688)\n",
      "precision 0.6743215031315241\n",
      "F1 feature 0.6598569969356486\n",
      "average_accuracy and average_accuracy_hm (0.667, 0.6663388305847077)\n",
      "model: knn\n",
      "recall1 and recall 2 (0.656, 0.614)\n",
      "precision 0.6295585412667947\n",
      "F1 feature 0.6425073457394711\n",
      "average_accuracy and average_accuracy_hm (0.635, 0.6343055118110237)\n",
      "model: svm\n",
      "recall1 and recall 2 (0.77, 0.734)\n",
      "precision 0.7432432432432432\n",
      "F1 feature 0.756385068762279\n",
      "average_accuracy and average_accuracy_hm (0.752, 0.7515691489361702)\n"
     ]
    }
   ],
   "source": [
    "model_list=[\"tree\",\"knn\",\"svm\"]\n",
    "for i in range(3):\n",
    "    print(\"model:\",model_list[i])\n",
    "    print(\"recall1 and recall 2\",recall(i))\n",
    "    print(\"precision\",precision(i))\n",
    "    print(\"F1 feature\",F1_feature(i))\n",
    "    print(\"average_accuracy and average_accuracy_hm\",average_accuracy_hm(i))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[323, 328, 385] [156, 193, 133] [344, 307, 367] [177, 172, 115]\n"
     ]
    }
   ],
   "source": [
    "print(TPlist,\n",
    "FPlist,\n",
    "TNlist,\n",
    "FNlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tree = joblib.load('tree.model')\n",
    "except:\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    tree = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "    joblib.dump(tree, 'tree.model')\n",
    "tree_predict=tree.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('mlpda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e0baf67eca4e7fa854f644d61b9ce9c5791eff3d5812e3fb6a3332a81a5d21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
